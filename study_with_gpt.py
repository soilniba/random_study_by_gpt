import os
import io
import re
import csv
import gzip
import json
import time
import urllib
import random
import string
import base64
import psutil
import hashlib
import datetime
import requests
from PIL import Image
from io import BytesIO
from loguru import logger
from pydub import AudioSegment
from revChatGPT.V3 import Chatbot
from requests_toolbelt import MultipartEncoder
import azure.cognitiveservices.speech as speechsdk
from config import *

filename_ext = os.path.basename(__file__)
file_name, file_ext = os.path.splitext(filename_ext)
logger.add(f"{file_name}.log", format="{time} - {level} - {message}", rotation="10 MB", compression="zip")    # æ·»åŠ æ—¥å¿—æ–‡ä»¶
if not openai_api_key:
    logger.error('éœ€è¦åœ¨config.pyä¸­è®¾ç½®openai_api_key')
    exit(1)
# temperature: float = 0.5,         æ§åˆ¶ç»“æœçš„éšæœºæ€§ï¼Œå¦‚æœå¸Œæœ›ç»“æœæ›´æœ‰åˆ›æ„å¯ä»¥å°è¯• 0.9ï¼Œæˆ–è€…å¸Œæœ›æœ‰å›ºå®šç»“æœå¯ä»¥å°è¯• 0.0
# top_p: float = 1.0,               ä¸€ä¸ªå¯ç”¨äºä»£æ›¿ temperature çš„å‚æ•°ï¼Œå¯¹åº”æœºå™¨å­¦ä¹ ä¸­ nucleus samplingï¼ˆæ ¸é‡‡æ ·ï¼‰ï¼Œå¦‚æœè®¾ç½® 0.1 æ„å‘³ç€åªè€ƒè™‘æ„æˆå‰ 10% æ¦‚ç‡è´¨é‡çš„ tokensã€‚ é€šå¸¸å»ºè®®ä¸è¦åŒæ—¶æ›´æ”¹è¿™ä¸¤è€…ã€‚
chatbot = Chatbot(api_key=openai_api_key, engine=gpt_model, proxy=openai_proxy, temperature = 0.9)
p = psutil.Process()                                        # è·å–å½“å‰è¿›ç¨‹çš„Processå¯¹è±¡
p.nice(psutil.IDLE_PRIORITY_CLASS)                          # è®¾ç½®è¿›ç¨‹ä¸ºä½ä¼˜å…ˆçº§
script_dir = os.path.dirname(os.path.realpath(__file__))    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„è·¯å¾„
os.chdir(script_dir)                                        # åˆ‡æ¢å·¥ä½œç›®å½•åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•

Cookie = ''
user_agent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'
headers = {
    'User-Agent': user_agent, 
    'Connection': 'close',
    'Cookie': Cookie,
    'Accept-Encoding': 'gzip',
}

def search_bing_image(text, number):
    # å»é™¤ä¸­æ–‡å­—ç¬¦
    regex = re.compile('[^a-zA-Z0-9 ]+')
    query = regex.sub('', text)
    if len(query) < 5:
        query = text
    headers = {"Ocp-Apim-Subscription-Key": azure_api_key}
    url = f"https://api.bing.microsoft.com/v7.0/images/search?q={query}&count={number * 2 + 2}&imageType=Photo&size=Large" #å¤šè·å–å‡ å¼ é¿å…å‡ºç°ä¸‹è½½ä¸äº†çš„å›¾ç‰‡
    response = requests.get(url, headers=headers)
    data = response.json()
    if response.status_code != 200:
        send_error_msg(f'æœç´¢å›¾ç‰‡å¤±è´¥: {data}')
        return
    if "value" in data:
        return down_up_images(data, number)

def down_up_images(data, number):
    image_urls = [item["contentUrl"] for item in data["value"]]
    image_key_list = []
    image_base64_list = []
    image_url_list = []
    for url in image_urls:
        try:
            response = requests.get(url)
            img = Image.open(BytesIO(response.content))
            img = img.convert("RGB")  # è½¬æ¢ä¸ºRGBæ¨¡å¼
            buffered = BytesIO()
            img.save(buffered, format="JPEG")
            image_bytes = buffered.getvalue()
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            image_md5 = hashlib.md5(image_bytes).hexdigest()
            image_base64_list.append({
                'base64': image_base64,
                'md5': image_md5,
            })
            image_url_list.append(url)
            if feishu_app_id and feishu_app_secret:
                if image_key := update_feishu_image(image_bytes):
                    image_key_list.append(image_key)
            if len(image_key_list) >= number:
                break
        except Exception as e:
            # send_error_msg(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {url}\n{e}")
            logger.error(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {url}\n{e}")
    return image_key_list, image_url_list, image_base64_list

feishu_token = None
def get_feishu_token():
    global feishu_token
    if not feishu_token:
        data = json.dumps({
            "app_id": feishu_app_id,
            "app_secret": feishu_app_secret,
        })
        response = requests.post('https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal', headers=headers, data=data)
        responsejson = json.loads(response.text)
        feishu_token = responsejson.get('tenant_access_token')
    return feishu_token

def get_feishu_chats_id(chat_name):
    feishu_token = get_feishu_token()
    if not feishu_token:
        return
    headers = {
        'Content-Type': 'application/json; charset=utf-8',
        'Authorization': f'Bearer {feishu_token}',
    }
    response = requests.get('https://open.feishu.cn/open-apis/im/v1/chats?user_id_type=open_id&page_size=50', headers=headers)
    responsejson = json.loads(response.text)
    # print(responsejson['data']['items'])
    if responsejson['code'] == 0:
        for item in responsejson['data']['items']:
            if chat_name in item['name']:
                logger.info(item['name'], item['chat_id'])
                return item['chat_id']
        send_error_msg(f'æœªæ‰¾åˆ°ç¾¤[{chat_name}]')
    else:
        send_error_msg('æ•°æ®è·å–å¼‚å¸¸', responsejson['msg'])

def update_feishu_image(file):
    feishu_token = get_feishu_token()
    if not feishu_token:
        return
    url = "https://open.feishu.cn/open-apis/im/v1/images"
    form = {'image_type': 'message',
            'image': (file)}
    multi_form = MultipartEncoder(form)
    headers = {
        'Authorization': f'Bearer {feishu_token}',
        'Content-Type': multi_form.content_type,
    }
    response = requests.request("POST", url, headers=headers, data=multi_form)
    # logger.debug(response.headers['X-Tt-Logid'])  # for debug or oncall
    # logger.debug(response.content)  # Response
    responsejson = json.loads(response.text)
    if responsejson['code'] == 0:
        return responsejson['data']['image_key']
    else:
        send_error_msg('ä¸Šä¼ å›¾ç‰‡å¤±è´¥', response.text)

def update_feishu_voice(voice_output_file_path, voice_duration):
    feishu_token = get_feishu_token()
    if not feishu_token:
        return
    with open(voice_output_file_path, 'rb') as file:
        bytes_data = file.read()
        form = {
            'file_type': 'opus',
            'file_name': 'voice.opus',
            'duration': str(int(voice_duration)),
            'file': ('voice.opus', io.BytesIO(bytes_data), 'audio/opus'),
        }
        multi_form = MultipartEncoder(form)
        headers = {
            'Authorization': f'Bearer {feishu_token}',
            'Content-Type': multi_form.content_type,
        }
        response = requests.request("POST", "https://open.feishu.cn/open-apis/im/v1/files", headers=headers, data=multi_form)
        logger.debug(response.headers['X-Tt-Logid'])  # for debug or oncall
        logger.debug(response.content)  # Response
        responsejson = json.loads(response.text)
        if responsejson['code'] == 0:
            return responsejson['data']['file_key']
        else:
            send_error_msg(f'ä¸Šä¼ éŸ³é¢‘å¤±è´¥ï¼š{response.text}')

# å°†OggéŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºmp3éŸ³é¢‘æ•°æ®
def ogg_to_mp3(voice_output_file_path):
    # å°†Oggæ•°æ®åŠ è½½åˆ°AudioSegmentå¯¹è±¡ä¸­
    ogg_audio = AudioSegment.from_file(voice_output_file_path, format="ogg")
    # å°†AudioSegmentå¯¹è±¡è½¬æ¢ä¸ºmp3æ ¼å¼çš„éŸ³é¢‘æ•°æ®
    mp3_audio = ogg_audio.export(format="mp3")
    # è¿”å›mp3æ ¼å¼çš„éŸ³é¢‘æ•°æ®
    return mp3_audio.read()

def upload_voice_file(voice_output_file_path, voice_duration):
    if not voice_file_server:
        return
    if mp3_data := ogg_to_mp3(voice_output_file_path):
        now = datetime.datetime.now() # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
        date_time_str = now.strftime("%Y%m%d%H%M%S")
        filename = f'voice{date_time_str}'
        headers = {"filename": filename}
        files = {'file': (filename, mp3_data, 'audio/mp3')}
        response = requests.post(f'{voice_file_server}/upload', files=files, headers=headers)
        if response.status_code != 200:
            return send_error_msg(f'ä¸Šä¼ éŸ³é¢‘å¤±è´¥ï¼š{response.text}')
        return f'{voice_file_server}/read/{filename}.mp3'

def send_feishu_robot(feishu_robot_key, feishu_msg):
    headers = {
        'Content-Type': 'application/json',
    }
    data = json.dumps({
        "msg_type": "post",
        "content": {
            "post": {
                "zh_cn": feishu_msg
            }
        }
    })
    response = requests.post(
        f'https://open.feishu.cn/open-apis/bot/v2/hook/{feishu_robot_key}',
        headers=headers,
        data=data,
    )
    return json.loads(response.text)


def send_feishu_robot_audio(chat_id, voice_key):
    feishu_token = get_feishu_token()
    if not feishu_token:
        return
    headers = {
        'Authorization': f'Bearer {feishu_token}',
        'Content-Type': 'application/json',
    }
    data = json.dumps({
        "receive_id": chat_id,
        "content": json.dumps({
            "file_key": voice_key,
        }),
        "msg_type": "audio"
    })
    response = requests.post(
        'https://open.feishu.cn/open-apis/im/v1/messages?receive_id_type=chat_id',
        headers = headers,
        data = data,
    )
    resp_json = json.loads(response.text)
    if resp_json.get('code') != 0:
        send_error_msg(resp_json)
    return resp_json

def send_worktool_robot(robot_key, robot_group_name, markdown_msg):
    headers = {
        'User-Agent': 'Apifox/1.0.0 (https://www.apifox.cn)',
        'Content-Type': 'application/json'
    }
    data = json.dumps({
        "socketType": 2,
        "list": [
            {
                "type": 203,
                "titleList": [
                    robot_group_name
                ],
                "receivedContent": markdown_msg
            }
        ]
    })
    response = requests.post(
        f'https://worktool.asrtts.cn/wework/sendRawMessage?robotId={robot_key}',
        headers=headers,
        data=data,
    )
    data = json.loads(response.text)
    if data.get('code') != 200:
        send_error_msg(f'ä¼ä¸šå¾®ä¿¡æœºå™¨äººå‘é€å¤±è´¥: {data}')
    logger.info(response.text)

def send_worktool_robot_file(robot_key, robot_group_name, markdown_msg, file_url, type):
    if not file_url:
        send_worktool_robot(robot_key, robot_group_name, markdown_msg)
        return
    filename = os.path.basename(urllib.parse.urlparse(file_url).path)
    # filetype = os.path.splitext(filename)[1]
    # if filetype in ['.png', '.jpg', '.jpeg']:
    headers = {
        'User-Agent': 'Apifox/1.0.0 (https://www.apifox.cn)',
        'Content-Type': 'application/json'
    }
    data = json.dumps({
    "socketType": 2,
    "list": [
        {
            "type": 218,
            "titleList": [
                robot_group_name
            ],
            "objectName": filename,
            "fileUrl": file_url,
            "fileType": type,
            "extraText": markdown_msg
        }
    ]
    })
    response = requests.post(
        f'https://worktool.asrtts.cn/wework/sendRawMessage?robotId={robot_key}',
        headers=headers,
        data=data,
    )
    data = json.loads(response.text)
    if data.get('code') != 200:
        send_error_msg(f'ä¼ä¸šå¾®ä¿¡æœºå™¨äººå‘é€å¤±è´¥: {data}')
    logger.info(response.text)
    return

def send_wx_robot(wx_robot_key, markdown_msg):
    headers = {
        'Content-Type': 'application/json',
    }
    data = json.dumps({
        "msgtype": "markdown", 
        "markdown": { "content": markdown_msg },
    })
    response = requests.post(
        f'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key={wx_robot_key}',
        headers=headers,
        data=data,
    )

def send_wx_robot_image(wx_robot_key, image_data):
    headers = {
        'Content-Type': 'application/json',
    }
    data = json.dumps({
        "msgtype": "image",
        "image": image_data
    })
    response = requests.post(
        f'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key={wx_robot_key}',
        headers=headers,
        data=data,
    )

def send_error_msg(text):
    if feishu_robot_error:
        text_msg = text
        feishu_msg = {"content": []}
        feishu_msg["content"].append([
            {
                "tag": "text",
                "text": text_msg
            },
        ])
        send_feishu_robot(feishu_robot_error, feishu_msg)
    if wx_robot_error:
        send_wx_robot(wx_robot_error, text)
    if worktool_robot_key and worktool_robot_group_error:
        send_worktool_robot(worktool_robot_key, worktool_robot_group_error, text)
    logger.error(text)

def send_message(text, answer_key, image_key_list, image_urls, image_base64_list, voice_key, voice_http_url):
    # title = 'ğŸŒ»å°è‘µèŠ±å¦ˆå¦ˆè¯¾å ‚å¼€è¯¾å•¦ï¼š'
    search_href = f'https://www.bing.com/search?q={answer_key}'
    text = re.sub('\n+', '\n', text or '')
    if feishu_robot_key := feishu_robot_study:
        feishu_msg = {"content": []}
        # feishu_msg["title"] = title
        feishu_msg["content"].append([
            {
                "tag": "text",
                "text": text
            },
        ])
        feishu_msg["content"].append([
            {
                "tag": "a",
                "text": 'æœç´¢æ›´å¤šç›¸å…³ä¿¡æ¯',
                "href": search_href
            },
        ])
        if image_key_list:
            feishu_msg["content"].append([
                {
                    "tag": "img",
                    "image_key": image_key,
                }
                for image_key in image_key_list
            ])
        if voice_key:
            send_feishu_robot_audio(get_feishu_chats_id(feishu_group_name), voice_key)
        send_feishu_robot(feishu_robot_key, feishu_msg)
    if wx_robot_key := wx_robot_study:
        # wx_msg = f'{title}\n{text}\n[æœç´¢æ›´å¤šç›¸å…³ä¿¡æ¯]({search_href})'
        wx_msg = f'{text}\n[æœç´¢æ›´å¤šç›¸å…³ä¿¡æ¯]({search_href})'
        send_wx_robot(wx_robot_key, wx_msg)
        for image_base64 in image_base64_list:
            send_wx_robot_image(wx_robot_key, image_base64)
    if worktool_robot_key:
        if worktool_robot_group_name := worktool_robot_group_study:
            # search_href = urllib.parse.quote(search_href, safe=':/?&=')
            # worktool_msg = f'{text}\näº†è§£æ›´å¤š:{search_href}'
            send_worktool_robot_file(worktool_robot_key, worktool_robot_group_name, None, image_urls[0], 'image')
            send_worktool_robot_file(worktool_robot_key, worktool_robot_group_name, text, voice_http_url, 'audio')

def random_project():
    with open("study_category_expand.json", "r", encoding="utf-8") as f:
        categories = json.load(f)

    total_subcategories = len(categories)
    subcategories_index_max = 0
    for subcategories_key in categories.keys():
        subcategories = categories[subcategories_key]['data']
        # categories[subcategories_key]['index'] = 0
        subcategories_index = categories[subcategories_key]['index']
        if subcategories_index > subcategories_index_max:
            subcategories_index_max = subcategories_index

    # éšæœºé€‰å‡ºä¸€ä¸ªæœªä½¿ç”¨çš„å¤§ç±»
    for _ in range(total_subcategories * 2):
        subcategories_key = random.choice(list(categories.keys()))
        subcategories_index = categories[subcategories_key]['index']
        if subcategories_index <= 0 or abs(subcategories_index_max - subcategories_index) >= total_subcategories * 0.6:
            categories[subcategories_key]['index'] = subcategories_index_max + 1
            subcategories = categories[subcategories_key]['data']
            sub2categories_key, project_key = random_subcategorie(subcategories)

            # å°†æ›´æ–°åçš„category.jsonå†™å›æ–‡ä»¶
            with open("study_category_expand.json", "w", encoding="utf-8") as f:
                json.dump(categories, f, ensure_ascii=False, indent=4)
            return {
                'subcategorie': subcategories_key,
                'sub2categorie': sub2categories_key,
                'project': project_key,
            }

def random_subcategorie(subcategories):
    project_index_max = 0
    total_projects = 0
    # å…ˆéå†ä¸€éprojectæ€»æ•°å’Œæœ€å¤§index
    for sub2categories_key in subcategories:
        sub2categories = subcategories[sub2categories_key]
        total_projects += len(sub2categories)
        for project_key in sub2categories:
            # sub2categories[project_key] = 0
            project_index = sub2categories[project_key]
            if project_index > project_index_max:
                project_index_max = project_index
    # å†é€‰ä¸€ä¸ªæœ€è¿‘æœªä½¿ç”¨çš„é¡¹ç›®
    for _ in range(total_projects * 2):
        sub2categories_key = random.choice(list(subcategories.keys()))
        sub2categories = subcategories[sub2categories_key]
        project_key = random.choice(list(sub2categories.keys()))
        project_index = sub2categories[project_key]
        if project_index <= 0 or abs(project_index_max - project_index) >= total_projects * 0.6:
            sub2categories[project_key] = project_index_max + 1
            return sub2categories_key, project_key

def ask_gpt(project):
    # è®¾ç½®è¦å‘é€åˆ°APIçš„æç¤ºè¯­
    system_prompt_splice = system_prompt.format(project["subcategorie"])
    user_prompt_splice = user_prompt.format(project["sub2categorie"], project["project"])
    message = [
        {'role': 'system', 'content': system_prompt_splice},
        {'role': 'user', 'content': user_prompt_splice},
    ]
    logger.info(message)
    try:
        chatbot.reset(system_prompt=system_prompt_splice)
        reply = chatbot.ask(user_prompt_splice)
        tokens = chatbot.get_token_count()
        logger.info(f"[ChatGPT] reply={reply}, total_tokens={tokens}")
        return reply
    except Exception as e:
        send_error_msg(f'openai api error:{e}')

def text_to_voice(text):
    # è®¾ç½®è¯­éŸ³åˆæˆçš„é…ç½®
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    # æ³¨æ„ï¼šè¯­éŸ³è®¾ç½®ä¸ä¼šè¦†ç›–è¾“å…¥ SSML ä¸­çš„è¯­éŸ³å…ƒç´ ã€‚
    ssml_format = random.choice(ssml_templete)
    logger.info(f'éšæœºéŸ³è‰²{ssml_format}')
    ssml_text = ssml_format.format(text)

    # è®¾ç½®è¾“å‡ºæ ¼å¼ä¸º Ogg48Khz16BitMonoOpus
    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat['Ogg48Khz16BitMonoOpus'])

    # å°†éŸ³é¢‘è¾“å‡ºé…ç½®è®¾ç½®ä¸ºå†…å­˜æµï¼Œè€Œä¸æ˜¯æ–‡ä»¶
    voice_output_file_path = 'voice_output_tmp'
    audio_config = speechsdk.audio.AudioOutputConfig(filename=voice_output_file_path)

    # ä½¿ç”¨è¯­éŸ³åˆæˆå™¨å°†æ–‡æœ¬åˆæˆä¸ºéŸ³é¢‘æµ
    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
    result = speech_synthesizer.speak_ssml_async(ssml_text).get()

    # æ£€æŸ¥åˆæˆç»“æœ
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        # è·å–éŸ³é¢‘æŒç»­æ—¶é—´
        duration = result.audio_duration.total_seconds() * 1000
        logger.info(
            f"æˆåŠŸåˆæˆæ–‡æœ¬ [{text[:10]}] çš„è¯­éŸ³ã€‚éŸ³é¢‘æ—¶é•¿ä¸º {duration} æ¯«ç§’"
        )
        return voice_output_file_path, duration
    elif result.reason == speechsdk.ResultReason.Canceled:
        # å¦‚æœåˆæˆè¢«å–æ¶ˆï¼Œåˆ™è®°å½•é”™è¯¯ä¿¡æ¯
        cancellation_details = result.cancellation_details
        send_error_msg(f"è¯­éŸ³åˆæˆè¢«å–æ¶ˆï¼š{cancellation_details.reason}")
        if cancellation_details.reason == speechsdk.CancellationReason.Error:
            send_error_msg(f"é”™è¯¯è¯¦æƒ…ï¼š{cancellation_details.error_details}")

def save_to_csv(project):
    filename = 'study_answer_save.csv'

    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºæ–‡ä»¶
    if not os.path.exists(filename):
        with open(filename, 'w+', newline='', encoding='utf-8') as f:
            pass

    # æ‰“å¼€CSVæ–‡ä»¶ï¼Œä½¿ç”¨è¿½åŠ æ¨¡å¼
    with open(filename, 'a', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['time', 'subcategorie', 'sub2categorie', 'project', 'answer', 'images'])
        # å¦‚æœæ–‡ä»¶æ˜¯ç©ºçš„ï¼Œåˆ™å…ˆå†™å…¥è¡¨å¤´
        if os.path.getsize(filename) == 0:
            writer.writeheader()
        writer.writerow(project)  # è¿½åŠ æ•°æ®

if __name__ == '__main__':
    for _ in range(knowledge_number):
        project = random_project()
        logger.info(project)
        for _ in range(5):
            if answer:= ask_gpt(project):
                answer_key = answer.split('\n')[0]
                voice_key = None
                voice_http_url = None
                if azure_api_key:
                    image_key_list, image_urls, image_base64_list = search_bing_image(answer_key, 2) or (None, [], None)
                if speech_key and service_region:
                    voice_output_file_path, voice_duration = text_to_voice(answer) or (None, None)
                    if voice_output_file_path and voice_duration:
                        voice_key = update_feishu_voice(voice_output_file_path, voice_duration)
                        voice_http_url = upload_voice_file(voice_output_file_path, voice_duration)
                send_message(answer, answer_key, image_key_list, image_urls, image_base64_list, voice_key, voice_http_url)
                project['answer'] = answer
                project['images'] = image_urls
                project['time'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                save_to_csv(project)
                break
            time.sleep(10)
